{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3. UCU Acoustic School Home task\n",
    "\n",
    "## Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from whisper import Whisper, log_mel_spectrogram, pad_or_trim\n",
    "from whisper.tokenizer import get_tokenizer\n",
    "from task1 import wer_torch\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchaudio.datasets import LIBRISPEECH\n",
    "from torchaudio.compliance.kaldi import mfcc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_BATCH_SIZE = 3\n",
    "DEFAULT_LEARNING_RATE = 1e-3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset ( LIBRISPEECH ):\n",
    "    def __init__(self, root, tokenizer, url=\"train-clean-100\"):\n",
    "        super().__init__(\".\", url=url, download=True)\n",
    "        self.root = root\n",
    "        self.tokenizer = tokenizer    \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        wav, sr, text, speaker_id, chapter_id, utterance_id = super().__getitem__(index)\n",
    "\n",
    "        padded_wav = pad_or_trim(wav)\n",
    "        spectrogram = log_mel_spectrogram(padded_wav)\n",
    "\n",
    "        text = text.lower()\n",
    "\n",
    "        tokenized_text = [*self.tokenizer.sot_sequence_including_notimestamps] + self.tokenizer.encode(text)\n",
    "        tokenized_labels = tokenized_text[1:] + [self.tokenizer.eot]\n",
    "\n",
    "        spectrogram = spectrogram.squeeze()\n",
    "\n",
    "        return spectrogram, tokenized_labels, tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn (batch):\n",
    "    spectrograms, labels, texts = zip(*batch)\n",
    "\n",
    "    max_label_len = max([len(label) for label in labels])\n",
    "    padded_labels = [label + [0] * (max_label_len - len(label)) for label in labels]\n",
    "\n",
    "    max_text_len = max([len(text) for text in texts])\n",
    "    padded_texts = [text + [0] * (max_text_len - len(text)) for text in texts]\n",
    "\n",
    "    spectrograms = torch.stack([torch.FloatTensor(spec) for spec in spectrograms])\n",
    "    padded_labels = torch.LongTensor(padded_labels)\n",
    "    padded_texts = torch.LongTensor(padded_texts)\n",
    "\n",
    "    return spectrograms, padded_labels, padded_texts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer :\n",
    "    def __init__(self,\n",
    "            model: Whisper, train_dataset , valid_dataset, output_dir, lang, device, n_epoch, \n",
    "            batch_size=DEFAULT_BATCH_SIZE, lr=DEFAULT_LEARNING_RATE):\n",
    "        self.model = model\n",
    "        self.train_dataset = train_dataset\n",
    "        self.valid_dataset = valid_dataset\n",
    "        self.output_dir = output_dir\n",
    "        self.lang = lang\n",
    "        self.device = device\n",
    "        self.n_epoch = n_epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.train_dataloader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "        self.valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.best_val_loss = float(\"inf\")\n",
    "\n",
    "    def train_step(self, input_spec, target_labels):\n",
    "        input_spec = input_spec.to(self.device)\n",
    "        target_labels = target_labels.to(self.device)\n",
    "\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        output = self.model(input_spec, target_labels)\n",
    "        output = output.transpose(1, 2)\n",
    "        loss = self.criterion(output, target_labels)\n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.n_epoch):\n",
    "            epoch_loss = 0.0\n",
    "\n",
    "            for input_spec, target_labels, _ in tqdm(self.train_dataloader):\n",
    "                loss = self.train_step(input_spec, target_labels)\n",
    "                epoch_loss += loss\n",
    "\n",
    "            epoch_loss = epoch_loss / len(self.train_dataloader)\n",
    "\n",
    "            print(f'EPOCH {epoch}')\n",
    "            print(f\"Training loss: {epoch_loss:.4f}\")\n",
    "            val_loss, wer = self.validate()\n",
    "\n",
    "            print(f'Validation loss: {val_loss}')\n",
    "            print(f'Validation WER:  {wer}')\n",
    "            if val_loss < self.best_val_loss:\n",
    "                self.best_val_loss = val_loss\n",
    "                torch.save(self.model.state_dict(), \"./whisper_librespeech_shevtsov.pt\")\n",
    "                print(\"Saved state dict!\")\n",
    "\n",
    "    \n",
    "    def validate (self):\n",
    "        val_loss = 0\n",
    "        wers = 0\n",
    "        self.model.eval()    \n",
    "        \n",
    "        for input_spec, target_labels, _ in tqdm(self.valid_dataloader):  # The last batch can't be a src\n",
    "            with torch.no_grad():\n",
    "                input_spec = input_spec.to(self.device)\n",
    "                target_labels = target_labels.to(self.device)\n",
    "                output = self.model(input_spec, target_labels)\n",
    "                output = output.transpose(1, 2)\n",
    "                loss = self.criterion(output, target_labels)              \n",
    "                # prediction = prediction.reshape(batch_size * seq_len, -1)   \n",
    "                loss = self.criterion(output, target_labels)\n",
    "                output_labels = output.argmax(dim=1)\n",
    "\n",
    "                # torch.nn.utils.clip_grad_norm_(self.model.parameters(), clip)\n",
    "                val_loss += loss.item() * input_spec.size()[0]\n",
    "                wers += wer_torch(output_labels, target_labels)\n",
    "                # cers += cer(prediction, y_val)\n",
    "        return val_loss / len(self.valid_dataloader), wers / len(self.valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_epoch = 1\n",
    "lang = 'en'\n",
    "tokenizer = get_tokenizer(True, language=lang, task='transcribe')\n",
    "train_dataset = MyDataset(\".\", tokenizer)\n",
    "valid_dataset = MyDataset(\".\", tokenizer, \"dev-clean\")\n",
    "output_dir = 'results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patriotic model loaded!\n"
     ]
    }
   ],
   "source": [
    "params = torch.load(\"patriotic_whisper_mixed_en_uk.pt\")\n",
    "model = whisper.load_model(\"tiny\", device=device)\n",
    "model.load_state_dict(params)\n",
    "print(\"Patriotic model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, train_dataset , valid_dataset, output_dir, lang, device, n_epoch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9513/9513 [1:29:07<00:00,  1.78it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "Training loss: 0.1773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 901/901 [18:34<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.10212980939721669\n",
      "Validation WER:  0.0036770787555724382\n",
      "Saved state dict!\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec, labels, text = next(trainer.valid_dataloader._get_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startoftranscript|><|en|><|transcribe|><|notimestamps|>mister quilter is the apostle of the middle classes and we are glad to welcome his gospel!!!!!!!!!!!!!!!!'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|en|><|transcribe|><|notimestamps|>mister forter is the apostle of the middle classes and we are glad to welcome his gospel<|endoftext|>!!!!!!!!!!!!!!!!'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec = spec.to(device)\n",
    "labels = labels.to(device)\n",
    "output = model(spec, labels)\n",
    "output_text = output.argmax(dim=2)\n",
    "tokenizer.decode(output_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
